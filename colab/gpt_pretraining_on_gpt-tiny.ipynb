{"cells":[{"cell_type":"markdown","metadata":{"id":"w8GkPIVd2uOY"},"source":["#Optimizer AdamW vs Sophia\n","#中文GPT预训练框架\n"]},{"cell_type":"markdown","source":["#Changelog\n","2023/6/1 新增sample，"],"metadata":{"id":"fWFa45vYMogO"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"7v3GObGOKDMJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05c3e2dd-1ac3-46d4-e638-a4339ba4a76d","executionInfo":{"status":"ok","timestamp":1685625116639,"user_tz":-480,"elapsed":4352,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.11\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Python 3.10.11\n"]}],"source":["!python -V\n","#!pip3 install --pre torch --index-url https://download.pytorch.org/whl/nightly/cpu\n","#!pip3 install numpy --pre torch --force-reinstall --index-url https://download.pytorch.org/whl/nightly/cu117\n","!pip install transformers datasets tiktoken\n","!python -V"]},{"cell_type":"markdown","source":["#Build Train and Dev binary files.\n","Manually move generated train.bin and dev.bin to data/web/ folder."],"metadata":{"id":"9CrWq_m8M0-1"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python prepare.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujMLRy43M0W-","executionInfo":{"status":"ok","timestamp":1685107030705,"user_tz":-480,"elapsed":21567,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"0702d19c-323c-4b96-be7c-70bee5ee1035"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-dd35d0846ce47d07/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n","Downloading data files: 100% 1/1 [00:00<00:00, 1429.06it/s]\n","Extracting data files: 100% 1/1 [00:00<00:00, 89.80it/s]\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-dd35d0846ce47d07/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n","100% 1/1 [00:00<00:00, 148.39it/s]\n","num_proc must be <= 6. Reducing num_proc to 6 for dataset of size 6.\n","tokenization finished\n","writing /content/drive/MyDrive/Code/train.bin...\n","100% 9996/9996 [00:06<00:00, 1429.12it/s]\n","writing /content/drive/MyDrive/Code/val.bin...\n","100% 6/6 [00:00<00:00, 1096.55it/s]\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python train.py --device=cuda --compile=True --dtype=float16 --eval_iters=1 --log_interval=10 --block_size=64 --batch_size=12 --n_layer=2 --n_head=2 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rKfAQXJN4uN","executionInfo":{"status":"ok","timestamp":1685353631640,"user_tz":-480,"elapsed":854316,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"fc2ab97a-fd97-460d-cd38-e5f98e35e2d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding: device = cuda\n","Overriding: compile = True\n","Overriding: dtype = float16\n","Overriding: eval_iters = 1\n","Overriding: log_interval = 10\n","Overriding: block_size = 64\n","Overriding: batch_size = 12\n","Overriding: n_layer = 2\n","Overriding: n_head = 2\n","Overriding: n_embd = 128\n","Overriding: max_iters = 2000\n","Overriding: lr_decay_iters = 2000\n","Overriding: dropout = 0.1\n","tokens per iteration will be: 30,720\n","Initializing a new model from scratch\n","defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n","number of parameters: 6.83M\n","using fused AdamW: True\n","compiling the model... (takes a ~minute)\n","step 0: train loss 10.8408, val loss 10.8501\n","[2023-05-29 09:34:05,564] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n","iter 0: loss 10.8481, time 158208.56ms, mfu -100.00%\n","iter 10: loss 10.8315, time 344.85ms, mfu 1.18%\n","iter 20: loss 10.8313, time 345.21ms, mfu 1.18%\n","iter 30: loss 10.8077, time 345.97ms, mfu 1.18%\n","iter 40: loss 10.7704, time 357.67ms, mfu 1.17%\n","iter 50: loss 10.6867, time 345.42ms, mfu 1.17%\n","iter 60: loss 10.6302, time 345.40ms, mfu 1.17%\n","iter 70: loss 10.5344, time 345.53ms, mfu 1.17%\n","iter 80: loss 10.4827, time 345.53ms, mfu 1.17%\n","iter 90: loss 10.3990, time 345.41ms, mfu 1.17%\n","iter 100: loss 10.3117, time 345.43ms, mfu 1.17%\n","iter 110: loss 10.2424, time 345.55ms, mfu 1.17%\n","iter 120: loss 10.1474, time 345.51ms, mfu 1.17%\n","iter 130: loss 10.0717, time 345.36ms, mfu 1.17%\n","iter 140: loss 9.9603, time 345.04ms, mfu 1.17%\n","iter 150: loss 9.8575, time 345.50ms, mfu 1.17%\n","iter 160: loss 9.7571, time 355.84ms, mfu 1.17%\n","iter 170: loss 9.6300, time 345.73ms, mfu 1.17%\n","iter 180: loss 9.4630, time 345.42ms, mfu 1.17%\n","iter 190: loss 9.3293, time 345.38ms, mfu 1.17%\n","iter 200: loss 9.2073, time 345.75ms, mfu 1.17%\n","iter 210: loss 9.0210, time 345.55ms, mfu 1.17%\n","iter 220: loss 8.8707, time 352.53ms, mfu 1.17%\n","iter 230: loss 8.7144, time 345.61ms, mfu 1.17%\n","iter 240: loss 8.5413, time 345.81ms, mfu 1.17%\n","iter 250: loss 8.3536, time 345.67ms, mfu 1.17%\n","iter 260: loss 8.1920, time 346.04ms, mfu 1.17%\n","iter 270: loss 8.0176, time 345.72ms, mfu 1.17%\n","iter 280: loss 7.8425, time 345.74ms, mfu 1.17%\n","iter 290: loss 7.6509, time 345.64ms, mfu 1.17%\n","iter 300: loss 7.4252, time 345.56ms, mfu 1.17%\n","iter 310: loss 7.1614, time 345.79ms, mfu 1.17%\n","iter 320: loss 6.9527, time 346.06ms, mfu 1.17%\n","iter 330: loss 6.8113, time 346.07ms, mfu 1.17%\n","iter 340: loss 6.5628, time 346.12ms, mfu 1.17%\n","iter 350: loss 6.3815, time 345.85ms, mfu 1.17%\n","iter 360: loss 6.1980, time 345.96ms, mfu 1.17%\n","iter 370: loss 6.0181, time 346.31ms, mfu 1.17%\n","iter 380: loss 5.9217, time 345.76ms, mfu 1.17%\n","iter 390: loss 5.6828, time 345.87ms, mfu 1.17%\n","iter 400: loss 5.6028, time 345.72ms, mfu 1.17%\n","iter 410: loss 5.3850, time 345.43ms, mfu 1.17%\n","iter 420: loss 5.2709, time 345.74ms, mfu 1.17%\n","iter 430: loss 5.2024, time 346.44ms, mfu 1.17%\n","iter 440: loss 5.1336, time 345.98ms, mfu 1.17%\n","iter 450: loss 4.9926, time 352.74ms, mfu 1.17%\n","iter 460: loss 4.9722, time 346.09ms, mfu 1.17%\n","iter 470: loss 4.9876, time 345.88ms, mfu 1.17%\n","iter 480: loss 4.8804, time 346.10ms, mfu 1.17%\n","iter 490: loss 4.8117, time 346.33ms, mfu 1.17%\n","iter 500: loss 4.8921, time 346.03ms, mfu 1.17%\n","iter 510: loss 4.6862, time 346.00ms, mfu 1.17%\n","iter 520: loss 4.6646, time 346.00ms, mfu 1.17%\n","iter 530: loss 4.5774, time 346.06ms, mfu 1.17%\n","iter 540: loss 4.5247, time 346.04ms, mfu 1.17%\n","iter 550: loss 4.5844, time 346.42ms, mfu 1.17%\n","iter 560: loss 4.4617, time 346.43ms, mfu 1.17%\n","iter 570: loss 4.4506, time 354.08ms, mfu 1.17%\n","iter 580: loss 4.3465, time 356.69ms, mfu 1.17%\n","iter 590: loss 4.3086, time 346.03ms, mfu 1.17%\n","iter 600: loss 4.2726, time 345.97ms, mfu 1.17%\n","iter 610: loss 4.2486, time 346.06ms, mfu 1.17%\n","iter 620: loss 4.1412, time 346.49ms, mfu 1.17%\n","iter 630: loss 4.1924, time 352.56ms, mfu 1.17%\n","iter 640: loss 4.1967, time 346.09ms, mfu 1.17%\n","iter 650: loss 4.0031, time 346.16ms, mfu 1.17%\n","iter 660: loss 4.0660, time 346.31ms, mfu 1.17%\n","iter 670: loss 4.1868, time 346.50ms, mfu 1.17%\n","iter 680: loss 3.9572, time 346.57ms, mfu 1.17%\n","iter 690: loss 3.9847, time 346.21ms, mfu 1.17%\n","iter 700: loss 3.9644, time 346.25ms, mfu 1.17%\n","iter 710: loss 3.7939, time 346.34ms, mfu 1.17%\n","iter 720: loss 3.7927, time 346.40ms, mfu 1.17%\n","iter 730: loss 3.7531, time 346.23ms, mfu 1.17%\n","iter 740: loss 3.8578, time 346.32ms, mfu 1.17%\n","iter 750: loss 3.7024, time 346.05ms, mfu 1.17%\n","iter 760: loss 3.9370, time 345.94ms, mfu 1.17%\n","iter 770: loss 3.8320, time 346.29ms, mfu 1.17%\n","iter 780: loss 3.7993, time 346.26ms, mfu 1.17%\n","iter 790: loss 3.6670, time 346.09ms, mfu 1.17%\n","iter 800: loss 3.6936, time 346.28ms, mfu 1.17%\n","iter 810: loss 3.6980, time 346.28ms, mfu 1.17%\n","iter 820: loss 3.7008, time 345.98ms, mfu 1.17%\n","iter 830: loss 3.6243, time 346.07ms, mfu 1.17%\n","iter 840: loss 3.6435, time 346.25ms, mfu 1.17%\n","iter 850: loss 3.5737, time 346.19ms, mfu 1.17%\n","iter 860: loss 3.7011, time 346.46ms, mfu 1.17%\n","iter 870: loss 3.5259, time 346.30ms, mfu 1.17%\n","iter 880: loss 3.6181, time 345.82ms, mfu 1.17%\n","iter 890: loss 3.6623, time 346.22ms, mfu 1.17%\n","iter 900: loss 3.5955, time 345.89ms, mfu 1.17%\n","iter 910: loss 3.6428, time 345.94ms, mfu 1.17%\n","iter 920: loss 3.5505, time 345.89ms, mfu 1.17%\n","iter 930: loss 3.5141, time 364.44ms, mfu 1.17%\n","iter 940: loss 3.6001, time 346.08ms, mfu 1.17%\n","iter 950: loss 3.6127, time 346.29ms, mfu 1.17%\n","iter 960: loss 3.4118, time 346.20ms, mfu 1.17%\n","iter 970: loss 3.4269, time 345.97ms, mfu 1.17%\n","iter 980: loss 3.6483, time 346.08ms, mfu 1.17%\n","iter 990: loss 3.4990, time 346.30ms, mfu 1.17%\n","iter 1000: loss 3.4499, time 345.82ms, mfu 1.17%\n","iter 1010: loss 3.5002, time 346.10ms, mfu 1.17%\n","iter 1020: loss 3.3691, time 346.11ms, mfu 1.17%\n","iter 1030: loss 3.4753, time 346.07ms, mfu 1.17%\n","iter 1040: loss 3.4100, time 346.06ms, mfu 1.17%\n","iter 1050: loss 3.7149, time 350.93ms, mfu 1.17%\n","iter 1060: loss 3.4860, time 346.31ms, mfu 1.17%\n","iter 1070: loss 3.4054, time 345.71ms, mfu 1.17%\n","iter 1080: loss 3.5333, time 345.83ms, mfu 1.17%\n","iter 1090: loss 3.4090, time 346.05ms, mfu 1.17%\n","iter 1100: loss 3.4449, time 346.40ms, mfu 1.17%\n","iter 1110: loss 3.4240, time 347.91ms, mfu 1.17%\n","iter 1120: loss 3.4017, time 345.80ms, mfu 1.17%\n","iter 1130: loss 3.5250, time 345.64ms, mfu 1.17%\n","iter 1140: loss 3.3592, time 345.97ms, mfu 1.17%\n","iter 1150: loss 3.4625, time 346.26ms, mfu 1.17%\n","iter 1160: loss 3.4658, time 345.87ms, mfu 1.17%\n","iter 1170: loss 3.3928, time 348.41ms, mfu 1.17%\n","iter 1180: loss 3.5023, time 345.94ms, mfu 1.17%\n","iter 1190: loss 3.3716, time 345.86ms, mfu 1.17%\n","iter 1200: loss 3.2900, time 345.91ms, mfu 1.17%\n","iter 1210: loss 3.2653, time 346.04ms, mfu 1.17%\n","iter 1220: loss 3.2609, time 346.02ms, mfu 1.17%\n","iter 1230: loss 3.3436, time 346.62ms, mfu 1.17%\n","iter 1240: loss 3.3383, time 345.94ms, mfu 1.17%\n","iter 1250: loss 3.2632, time 346.37ms, mfu 1.17%\n","iter 1260: loss 3.4003, time 346.02ms, mfu 1.17%\n","iter 1270: loss 3.3800, time 345.89ms, mfu 1.17%\n","iter 1280: loss 3.1914, time 346.37ms, mfu 1.17%\n","iter 1290: loss 3.2839, time 345.91ms, mfu 1.17%\n","iter 1300: loss 3.2506, time 345.65ms, mfu 1.17%\n","iter 1310: loss 3.3650, time 346.01ms, mfu 1.17%\n","iter 1320: loss 3.3786, time 345.76ms, mfu 1.17%\n","iter 1330: loss 3.0833, time 346.08ms, mfu 1.17%\n","iter 1340: loss 3.2450, time 358.67ms, mfu 1.17%\n","iter 1350: loss 3.3935, time 345.98ms, mfu 1.17%\n","iter 1360: loss 3.4024, time 345.76ms, mfu 1.17%\n","iter 1370: loss 3.4104, time 345.90ms, mfu 1.17%\n","iter 1380: loss 3.2447, time 345.59ms, mfu 1.17%\n","iter 1390: loss 3.4637, time 345.86ms, mfu 1.17%\n","iter 1400: loss 3.1613, time 346.05ms, mfu 1.17%\n","iter 1410: loss 3.2091, time 345.96ms, mfu 1.17%\n","iter 1420: loss 3.2302, time 345.37ms, mfu 1.17%\n","iter 1430: loss 3.1846, time 345.88ms, mfu 1.17%\n","iter 1440: loss 3.4348, time 345.84ms, mfu 1.17%\n","iter 1450: loss 3.2920, time 345.79ms, mfu 1.17%\n","iter 1460: loss 3.2056, time 345.97ms, mfu 1.17%\n","iter 1470: loss 3.3918, time 345.67ms, mfu 1.17%\n","iter 1480: loss 3.2987, time 345.87ms, mfu 1.17%\n","iter 1490: loss 3.0457, time 345.83ms, mfu 1.17%\n","iter 1500: loss 3.1189, time 345.66ms, mfu 1.17%\n","iter 1510: loss 3.3586, time 345.95ms, mfu 1.17%\n","iter 1520: loss 3.1876, time 345.69ms, mfu 1.17%\n","iter 1530: loss 3.1832, time 346.02ms, mfu 1.17%\n","iter 1540: loss 3.3241, time 345.79ms, mfu 1.17%\n","iter 1550: loss 3.2933, time 345.84ms, mfu 1.17%\n","iter 1560: loss 3.1354, time 346.03ms, mfu 1.17%\n","iter 1570: loss 3.2391, time 346.21ms, mfu 1.17%\n","iter 1580: loss 3.0304, time 345.73ms, mfu 1.17%\n","iter 1590: loss 3.1051, time 347.20ms, mfu 1.17%\n","iter 1600: loss 3.0305, time 345.67ms, mfu 1.17%\n","iter 1610: loss 3.0442, time 345.92ms, mfu 1.17%\n","iter 1620: loss 3.0657, time 345.66ms, mfu 1.17%\n","iter 1630: loss 3.1369, time 346.24ms, mfu 1.17%\n","iter 1640: loss 3.1128, time 345.81ms, mfu 1.17%\n","iter 1650: loss 3.2136, time 351.01ms, mfu 1.17%\n","iter 1660: loss 3.2353, time 346.06ms, mfu 1.17%\n","iter 1670: loss 3.0765, time 345.68ms, mfu 1.17%\n","iter 1680: loss 3.1245, time 345.72ms, mfu 1.17%\n","iter 1690: loss 3.1432, time 345.86ms, mfu 1.17%\n","iter 1700: loss 3.1498, time 345.59ms, mfu 1.17%\n","iter 1710: loss 3.3698, time 345.76ms, mfu 1.17%\n","iter 1720: loss 3.0605, time 345.70ms, mfu 1.17%\n","iter 1730: loss 2.9454, time 345.78ms, mfu 1.17%\n","iter 1740: loss 3.0870, time 345.96ms, mfu 1.17%\n","iter 1750: loss 2.9863, time 345.88ms, mfu 1.17%\n","iter 1760: loss 3.1572, time 346.10ms, mfu 1.17%\n","iter 1770: loss 3.0763, time 346.41ms, mfu 1.17%\n","iter 1780: loss 3.0668, time 345.92ms, mfu 1.17%\n","iter 1790: loss 3.1002, time 345.86ms, mfu 1.17%\n","iter 1800: loss 3.0365, time 345.75ms, mfu 1.17%\n","iter 1810: loss 3.0814, time 345.87ms, mfu 1.17%\n","iter 1820: loss 2.9828, time 354.15ms, mfu 1.17%\n","iter 1830: loss 3.0642, time 345.88ms, mfu 1.17%\n","iter 1840: loss 3.0767, time 345.57ms, mfu 1.17%\n","iter 1850: loss 2.9436, time 345.66ms, mfu 1.17%\n","iter 1860: loss 3.0623, time 345.50ms, mfu 1.17%\n","iter 1870: loss 3.2196, time 346.03ms, mfu 1.17%\n","iter 1880: loss 2.9204, time 346.07ms, mfu 1.17%\n","iter 1890: loss 3.0537, time 345.64ms, mfu 1.17%\n","iter 1900: loss 2.9163, time 345.71ms, mfu 1.17%\n","iter 1910: loss 3.3092, time 345.96ms, mfu 1.17%\n","iter 1920: loss 3.0111, time 345.87ms, mfu 1.17%\n","iter 1930: loss 2.9878, time 345.96ms, mfu 1.17%\n","iter 1940: loss 3.1059, time 350.69ms, mfu 1.17%\n","iter 1950: loss 3.0262, time 345.74ms, mfu 1.17%\n","iter 1960: loss 2.9263, time 345.69ms, mfu 1.17%\n","Process ForkProcess-2:\n","Process ForkProcess-1:\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Code/train.py\", line 298, in <module>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n","    call_item = call_queue.get(block=True)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n","    call_item = call_queue.get(block=True)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","    X, Y = get_batch('train')\n","  File \"/content/drive/MyDrive/Code/train.py\", line 119, in get_batch\n","    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n","  File \"/content/drive/MyDrive/Code/train.py\", line 119, in <listcomp>\n","    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n","  File \"/usr/local/lib/python3.10/dist-packages/numpy/core/memmap.py\", line 288, in __array_finalize__\n","    def __array_finalize__(self, obj):\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python train_better.py --device=cuda --dtype=float16 --compile=True --eval_iters=1 --log_interval=10 --block_size=64 --batch_size=12 --n_layer=2 --n_head=2 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0n1rW-dRaQ-","executionInfo":{"status":"ok","timestamp":1685354346385,"user_tz":-480,"elapsed":714747,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"80575176-d155-400c-d137-123b76f0661d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","Overriding: compile = True\n","Overriding: eval_iters = 1\n","Overriding: log_interval = 10\n","Overriding: block_size = 64\n","Overriding: batch_size = 12\n","Overriding: n_layer = 2\n","Overriding: n_head = 2\n","Overriding: n_embd = 128\n","Overriding: max_iters = 2000\n","Overriding: lr_decay_iters = 2000\n","Overriding: dropout = 0.1\n","tokens per iteration will be: 30,720\n","Initializing a new model from scratch\n","defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n","number of parameters: 6.83M\n","compiling the model... (takes a ~minute)\n","step 0: train loss 10.8408, val loss 10.8501\n","[2023-05-29 09:47:27,814] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n","iter 0: loss 10.8481, time 15923.32ms, mfu -100.00%\n","iter 10: loss 10.8313, time 342.21ms, mfu 1.19%\n","iter 20: loss 10.8305, time 345.73ms, mfu 1.18%\n","iter 30: loss 10.8061, time 345.44ms, mfu 1.18%\n","iter 40: loss 10.7682, time 341.74ms, mfu 1.18%\n","iter 50: loss 10.6848, time 342.00ms, mfu 1.18%\n","iter 60: loss 10.6290, time 341.91ms, mfu 1.18%\n","iter 70: loss 10.5356, time 342.42ms, mfu 1.18%\n","iter 80: loss 10.4865, time 344.67ms, mfu 1.18%\n","iter 90: loss 10.4060, time 343.10ms, mfu 1.18%\n","iter 100: loss 10.3219, time 341.73ms, mfu 1.18%\n","iter 110: loss 10.2555, time 341.85ms, mfu 1.18%\n","iter 120: loss 10.1630, time 341.64ms, mfu 1.18%\n","iter 130: loss 10.0859, time 342.30ms, mfu 1.18%\n","iter 140: loss 9.9736, time 343.12ms, mfu 1.18%\n","iter 150: loss 9.8663, time 344.32ms, mfu 1.18%\n","iter 160: loss 9.7672, time 341.52ms, mfu 1.18%\n","iter 170: loss 9.6427, time 342.33ms, mfu 1.18%\n","iter 180: loss 9.4690, time 341.71ms, mfu 1.18%\n","iter 190: loss 9.3370, time 342.29ms, mfu 1.18%\n","iter 200: loss 9.2204, time 356.09ms, mfu 1.18%\n","iter 210: loss 9.0311, time 343.40ms, mfu 1.18%\n","iter 220: loss 8.8832, time 341.46ms, mfu 1.18%\n","iter 230: loss 8.7221, time 341.94ms, mfu 1.18%\n","iter 240: loss 8.5522, time 341.71ms, mfu 1.18%\n","iter 250: loss 8.3638, time 343.16ms, mfu 1.18%\n","iter 260: loss 8.1988, time 346.95ms, mfu 1.18%\n","iter 270: loss 8.0311, time 346.53ms, mfu 1.18%\n","iter 280: loss 7.8580, time 341.69ms, mfu 1.18%\n","iter 290: loss 7.6612, time 342.06ms, mfu 1.18%\n","iter 300: loss 7.4325, time 341.89ms, mfu 1.18%\n","iter 310: loss 7.1623, time 342.32ms, mfu 1.18%\n","iter 320: loss 6.9481, time 343.48ms, mfu 1.18%\n","iter 330: loss 6.8082, time 344.64ms, mfu 1.18%\n","iter 340: loss 6.5539, time 341.96ms, mfu 1.18%\n","iter 350: loss 6.3681, time 341.78ms, mfu 1.18%\n","iter 360: loss 6.1781, time 341.61ms, mfu 1.18%\n","iter 370: loss 5.9951, time 342.79ms, mfu 1.18%\n","iter 380: loss 5.9022, time 343.28ms, mfu 1.18%\n","iter 390: loss 5.6456, time 351.93ms, mfu 1.18%\n","iter 400: loss 5.5573, time 341.61ms, mfu 1.18%\n","iter 410: loss 5.3266, time 341.68ms, mfu 1.18%\n","iter 420: loss 5.2040, time 341.61ms, mfu 1.18%\n","iter 430: loss 5.1234, time 342.18ms, mfu 1.18%\n","iter 440: loss 5.0506, time 343.28ms, mfu 1.18%\n","iter 450: loss 4.8963, time 345.42ms, mfu 1.18%\n","iter 460: loss 4.8748, time 341.45ms, mfu 1.18%\n","iter 470: loss 4.8695, time 341.65ms, mfu 1.18%\n","iter 480: loss 4.7627, time 341.59ms, mfu 1.18%\n","iter 490: loss 4.6650, time 342.90ms, mfu 1.18%\n","iter 500: loss 4.7371, time 343.41ms, mfu 1.18%\n","iter 510: loss 4.5446, time 342.66ms, mfu 1.18%\n","iter 520: loss 4.4888, time 341.38ms, mfu 1.18%\n","iter 530: loss 4.3858, time 345.43ms, mfu 1.18%\n","iter 540: loss 4.3336, time 341.57ms, mfu 1.18%\n","iter 550: loss 4.3962, time 347.36ms, mfu 1.18%\n","iter 560: loss 4.2522, time 342.62ms, mfu 1.18%\n","iter 570: loss 4.2152, time 346.57ms, mfu 1.18%\n","iter 580: loss 4.0973, time 341.88ms, mfu 1.18%\n","iter 590: loss 4.0665, time 341.65ms, mfu 1.18%\n","iter 600: loss 4.0097, time 342.85ms, mfu 1.18%\n","iter 610: loss 3.9821, time 342.48ms, mfu 1.18%\n","iter 620: loss 3.8789, time 343.22ms, mfu 1.18%\n","iter 630: loss 3.9235, time 372.18ms, mfu 1.17%\n","iter 640: loss 3.9137, time 342.09ms, mfu 1.17%\n","iter 650: loss 3.7288, time 341.87ms, mfu 1.18%\n","iter 660: loss 3.7472, time 341.98ms, mfu 1.18%\n","iter 670: loss 3.9081, time 342.43ms, mfu 1.18%\n","iter 680: loss 3.6475, time 342.30ms, mfu 1.18%\n","iter 690: loss 3.6703, time 349.79ms, mfu 1.18%\n","iter 700: loss 3.6478, time 341.63ms, mfu 1.18%\n","iter 710: loss 3.4253, time 341.54ms, mfu 1.18%\n","iter 720: loss 3.4931, time 341.83ms, mfu 1.18%\n","iter 730: loss 3.3911, time 342.66ms, mfu 1.18%\n","iter 740: loss 3.4978, time 342.28ms, mfu 1.18%\n","iter 750: loss 3.3793, time 345.96ms, mfu 1.18%\n","iter 760: loss 3.6139, time 344.00ms, mfu 1.18%\n","iter 770: loss 3.4957, time 341.63ms, mfu 1.18%\n","iter 780: loss 3.4557, time 341.68ms, mfu 1.18%\n","iter 790: loss 3.3378, time 342.09ms, mfu 1.18%\n","iter 800: loss 3.3785, time 342.82ms, mfu 1.18%\n","iter 810: loss 3.3765, time 342.59ms, mfu 1.18%\n","iter 820: loss 3.3626, time 341.43ms, mfu 1.18%\n","iter 830: loss 3.2441, time 341.34ms, mfu 1.18%\n","iter 840: loss 3.2728, time 341.56ms, mfu 1.18%\n","iter 850: loss 3.1850, time 342.05ms, mfu 1.18%\n","iter 860: loss 3.2912, time 342.31ms, mfu 1.18%\n","iter 870: loss 3.1679, time 345.53ms, mfu 1.18%\n","iter 880: loss 3.2017, time 341.38ms, mfu 1.18%\n","iter 890: loss 3.2788, time 341.34ms, mfu 1.18%\n","iter 900: loss 3.2435, time 341.15ms, mfu 1.18%\n","iter 910: loss 3.2693, time 342.30ms, mfu 1.18%\n","iter 920: loss 3.1836, time 341.74ms, mfu 1.18%\n","iter 930: loss 3.0924, time 342.73ms, mfu 1.18%\n","iter 940: loss 3.2211, time 341.41ms, mfu 1.18%\n","iter 950: loss 3.1699, time 341.74ms, mfu 1.19%\n","iter 960: loss 3.0526, time 341.57ms, mfu 1.19%\n","iter 970: loss 3.0199, time 342.02ms, mfu 1.19%\n","iter 980: loss 3.2867, time 342.09ms, mfu 1.19%\n","iter 990: loss 3.0761, time 343.09ms, mfu 1.19%\n","iter 1000: loss 3.0717, time 341.42ms, mfu 1.19%\n","iter 1010: loss 3.0710, time 341.47ms, mfu 1.19%\n","iter 1020: loss 2.9833, time 341.25ms, mfu 1.19%\n","iter 1030: loss 3.0462, time 342.64ms, mfu 1.19%\n","iter 1040: loss 3.0468, time 342.80ms, mfu 1.19%\n","iter 1050: loss 3.3568, time 342.88ms, mfu 1.19%\n","iter 1060: loss 3.0611, time 341.19ms, mfu 1.19%\n","iter 1070: loss 2.9573, time 341.33ms, mfu 1.19%\n","iter 1080: loss 3.1298, time 341.31ms, mfu 1.19%\n","iter 1090: loss 3.0415, time 341.70ms, mfu 1.19%\n","iter 1100: loss 2.9408, time 342.74ms, mfu 1.19%\n","iter 1110: loss 3.0002, time 342.66ms, mfu 1.19%\n","iter 1120: loss 3.0039, time 341.26ms, mfu 1.19%\n","iter 1130: loss 3.1242, time 341.47ms, mfu 1.19%\n","iter 1140: loss 2.9916, time 341.26ms, mfu 1.19%\n","iter 1150: loss 3.0818, time 341.95ms, mfu 1.19%\n","iter 1160: loss 3.1376, time 342.57ms, mfu 1.19%\n","iter 1170: loss 3.0874, time 342.46ms, mfu 1.19%\n","iter 1180: loss 3.1850, time 341.25ms, mfu 1.19%\n","iter 1190: loss 2.9912, time 342.12ms, mfu 1.19%\n","iter 1200: loss 2.8514, time 341.07ms, mfu 1.19%\n","iter 1210: loss 2.9142, time 342.04ms, mfu 1.19%\n","iter 1220: loss 2.8830, time 343.33ms, mfu 1.19%\n","iter 1230: loss 2.9777, time 342.47ms, mfu 1.19%\n","iter 1240: loss 3.0156, time 341.22ms, mfu 1.19%\n","iter 1250: loss 2.8659, time 341.23ms, mfu 1.19%\n","iter 1260: loss 3.0771, time 341.33ms, mfu 1.19%\n","iter 1270: loss 3.0784, time 341.76ms, mfu 1.19%\n","iter 1280: loss 2.8454, time 342.64ms, mfu 1.19%\n","iter 1290: loss 2.9881, time 342.70ms, mfu 1.19%\n","iter 1300: loss 2.9563, time 341.34ms, mfu 1.19%\n","iter 1310: loss 3.0102, time 341.34ms, mfu 1.19%\n","iter 1320: loss 3.0270, time 341.22ms, mfu 1.19%\n","iter 1330: loss 2.7820, time 341.91ms, mfu 1.19%\n","iter 1340: loss 2.9004, time 342.63ms, mfu 1.19%\n","iter 1350: loss 3.0267, time 342.46ms, mfu 1.19%\n","iter 1360: loss 3.1302, time 341.41ms, mfu 1.19%\n","iter 1370: loss 3.0776, time 341.26ms, mfu 1.19%\n","iter 1380: loss 2.8352, time 341.27ms, mfu 1.19%\n","iter 1390: loss 3.1694, time 341.89ms, mfu 1.19%\n","iter 1400: loss 2.8799, time 353.08ms, mfu 1.18%\n","iter 1410: loss 2.8759, time 343.77ms, mfu 1.18%\n","iter 1420: loss 2.9531, time 341.37ms, mfu 1.18%\n","iter 1430: loss 2.8206, time 341.09ms, mfu 1.18%\n","iter 1440: loss 3.1701, time 341.31ms, mfu 1.18%\n","iter 1450: loss 3.0196, time 344.56ms, mfu 1.18%\n","iter 1460: loss 2.8902, time 342.39ms, mfu 1.18%\n","iter 1470: loss 3.0850, time 342.86ms, mfu 1.18%\n","iter 1480: loss 3.0056, time 341.21ms, mfu 1.18%\n","iter 1490: loss 2.8278, time 341.19ms, mfu 1.18%\n","iter 1500: loss 2.8521, time 341.35ms, mfu 1.18%\n","iter 1510: loss 3.0634, time 341.60ms, mfu 1.19%\n","iter 1520: loss 2.9318, time 342.51ms, mfu 1.19%\n","iter 1530: loss 2.9052, time 342.44ms, mfu 1.18%\n","iter 1540: loss 3.1231, time 341.43ms, mfu 1.19%\n","iter 1550: loss 3.0806, time 341.31ms, mfu 1.19%\n","iter 1560: loss 2.8635, time 341.23ms, mfu 1.19%\n","iter 1570: loss 3.0116, time 342.79ms, mfu 1.19%\n","iter 1580: loss 2.7719, time 343.46ms, mfu 1.19%\n","iter 1590: loss 2.8681, time 346.51ms, mfu 1.18%\n","iter 1600: loss 2.8125, time 341.26ms, mfu 1.18%\n","iter 1610: loss 2.8159, time 341.21ms, mfu 1.18%\n","iter 1620: loss 2.8558, time 341.42ms, mfu 1.18%\n","iter 1630: loss 2.9029, time 341.89ms, mfu 1.19%\n","iter 1640: loss 2.9602, time 342.49ms, mfu 1.19%\n","iter 1650: loss 3.0014, time 343.34ms, mfu 1.18%\n","iter 1660: loss 3.0600, time 341.12ms, mfu 1.19%\n","iter 1670: loss 2.8557, time 341.43ms, mfu 1.19%\n","iter 1680: loss 2.8922, time 341.52ms, mfu 1.19%\n","iter 1690: loss 2.9394, time 341.70ms, mfu 1.19%\n","iter 1700: loss 2.9047, time 342.79ms, mfu 1.19%\n","iter 1710: loss 3.1393, time 342.37ms, mfu 1.19%\n","iter 1720: loss 2.8546, time 341.31ms, mfu 1.19%\n","iter 1730: loss 2.7645, time 341.47ms, mfu 1.19%\n","iter 1740: loss 2.8350, time 341.17ms, mfu 1.19%\n","iter 1750: loss 2.7669, time 343.10ms, mfu 1.19%\n","iter 1760: loss 2.8970, time 342.95ms, mfu 1.19%\n","iter 1770: loss 2.9369, time 343.07ms, mfu 1.19%\n","iter 1780: loss 2.7768, time 341.19ms, mfu 1.19%\n","iter 1790: loss 2.8369, time 341.31ms, mfu 1.19%\n","iter 1800: loss 2.8384, time 342.55ms, mfu 1.19%\n","iter 1810: loss 2.8707, time 341.75ms, mfu 1.19%\n","iter 1820: loss 2.7835, time 850.20ms, mfu 1.11%\n","iter 1830: loss 2.8615, time 354.51ms, mfu 1.12%\n","iter 1840: loss 2.9300, time 384.98ms, mfu 1.11%\n","iter 1850: loss 2.7495, time 341.83ms, mfu 1.12%\n","iter 1860: loss 2.9558, time 342.75ms, mfu 1.13%\n","iter 1870: loss 2.9952, time 342.42ms, mfu 1.13%\n","iter 1880: loss 2.8011, time 341.38ms, mfu 1.14%\n","iter 1890: loss 2.9279, time 341.53ms, mfu 1.14%\n","iter 1900: loss 2.7623, time 341.24ms, mfu 1.15%\n","iter 1910: loss 3.0727, time 342.10ms, mfu 1.15%\n","iter 1920: loss 2.8964, time 342.50ms, mfu 1.15%\n","iter 1930: loss 2.8074, time 343.27ms, mfu 1.16%\n","iter 1940: loss 2.9930, time 341.88ms, mfu 1.16%\n","iter 1950: loss 2.8889, time 341.17ms, mfu 1.16%\n","iter 1960: loss 2.7209, time 341.50ms, mfu 1.17%\n","iter 1970: loss 2.8341, time 341.58ms, mfu 1.17%\n","iter 1980: loss 2.7966, time 341.91ms, mfu 1.17%\n","iter 1990: loss 2.9437, time 346.59ms, mfu 1.17%\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Code/train_better.py\", line 255, in <module>\n","    lr = get_lr(iter_num) if decay_lr else learning_rate\n","  File \"/content/drive/MyDrive/Code/train_better.py\", line 236, in get_lr\n","    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n","ZeroDivisionError: division by zero\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python train.py --device=cuda --dtype=float16 --compile=True --eval_iters=1 --log_interval=10 --block_size=64 --batch_size=12 --n_layer=2 --n_head=2 --n_embd=128 --max_iters=2000 --lr_decay_iters=800 --dropout=0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5hc38a8_r6E","executionInfo":{"status":"ok","timestamp":1685355949984,"user_tz":-480,"elapsed":713401,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"29fae827-011d-464a-b01e-08c85c97e9d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","Overriding: compile = True\n","Overriding: eval_iters = 1\n","Overriding: log_interval = 10\n","Overriding: block_size = 64\n","Overriding: batch_size = 12\n","Overriding: n_layer = 2\n","Overriding: n_head = 2\n","Overriding: n_embd = 128\n","Overriding: max_iters = 2000\n","Overriding: lr_decay_iters = 800\n","Overriding: dropout = 0.1\n","tokens per iteration will be: 30,720\n","Initializing a new model from scratch\n","defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n","number of parameters: 6.83M\n","using fused AdamW: True\n","compiling the model... (takes a ~minute)\n","step 0: train loss 10.8408, val loss 10.8501\n","[2023-05-29 10:14:11,008] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n","iter 0: loss 10.8481, time 14817.07ms, mfu -100.00%\n","iter 10: loss 10.8315, time 343.75ms, mfu 1.18%\n","iter 20: loss 10.8313, time 348.76ms, mfu 1.18%\n","iter 30: loss 10.8077, time 343.38ms, mfu 1.18%\n","iter 40: loss 10.7704, time 343.73ms, mfu 1.18%\n","iter 50: loss 10.6867, time 343.89ms, mfu 1.18%\n","iter 60: loss 10.6302, time 343.96ms, mfu 1.18%\n","iter 70: loss 10.5344, time 343.95ms, mfu 1.18%\n","iter 80: loss 10.4827, time 347.30ms, mfu 1.18%\n","iter 90: loss 10.3990, time 344.09ms, mfu 1.18%\n","iter 100: loss 10.3117, time 343.95ms, mfu 1.18%\n","iter 110: loss 10.2424, time 344.42ms, mfu 1.18%\n","iter 120: loss 10.1474, time 344.19ms, mfu 1.18%\n","iter 130: loss 10.0717, time 344.40ms, mfu 1.18%\n","iter 140: loss 9.9603, time 344.38ms, mfu 1.18%\n","iter 150: loss 9.8575, time 344.38ms, mfu 1.18%\n","iter 160: loss 9.7571, time 344.69ms, mfu 1.18%\n","iter 170: loss 9.6300, time 345.06ms, mfu 1.18%\n","iter 180: loss 9.4630, time 344.93ms, mfu 1.18%\n","iter 190: loss 9.3293, time 344.72ms, mfu 1.18%\n","iter 200: loss 9.2073, time 345.13ms, mfu 1.18%\n","iter 210: loss 9.0210, time 345.19ms, mfu 1.18%\n","iter 220: loss 8.8707, time 345.19ms, mfu 1.18%\n","iter 230: loss 8.7144, time 345.18ms, mfu 1.18%\n","iter 240: loss 8.5413, time 345.62ms, mfu 1.18%\n","iter 250: loss 8.3536, time 348.55ms, mfu 1.17%\n","iter 260: loss 8.1920, time 345.28ms, mfu 1.17%\n","iter 270: loss 8.0177, time 345.42ms, mfu 1.17%\n","iter 280: loss 7.8425, time 345.61ms, mfu 1.17%\n","iter 290: loss 7.6509, time 345.93ms, mfu 1.17%\n","iter 300: loss 7.4252, time 346.09ms, mfu 1.17%\n","iter 310: loss 7.1614, time 346.04ms, mfu 1.17%\n","iter 320: loss 6.9527, time 345.84ms, mfu 1.17%\n","iter 330: loss 6.8113, time 346.17ms, mfu 1.17%\n","iter 340: loss 6.5628, time 346.20ms, mfu 1.17%\n","iter 350: loss 6.3815, time 346.10ms, mfu 1.17%\n","iter 360: loss 6.1981, time 346.02ms, mfu 1.17%\n","iter 370: loss 6.0181, time 345.58ms, mfu 1.17%\n","iter 380: loss 5.9217, time 345.93ms, mfu 1.17%\n","iter 390: loss 5.6828, time 345.76ms, mfu 1.17%\n","iter 400: loss 5.6029, time 348.48ms, mfu 1.17%\n","iter 410: loss 5.3850, time 345.57ms, mfu 1.17%\n","iter 420: loss 5.2710, time 345.70ms, mfu 1.17%\n","iter 430: loss 5.2027, time 345.59ms, mfu 1.17%\n","iter 440: loss 5.1336, time 345.66ms, mfu 1.17%\n","iter 450: loss 4.9927, time 345.49ms, mfu 1.17%\n","iter 460: loss 4.9723, time 345.81ms, mfu 1.17%\n","iter 470: loss 4.9876, time 345.63ms, mfu 1.17%\n","iter 480: loss 4.8811, time 345.49ms, mfu 1.17%\n","iter 490: loss 4.8132, time 345.35ms, mfu 1.17%\n","iter 500: loss 4.8943, time 345.64ms, mfu 1.17%\n","iter 510: loss 4.6868, time 345.59ms, mfu 1.17%\n","iter 520: loss 4.6645, time 345.56ms, mfu 1.17%\n","iter 530: loss 4.5790, time 345.80ms, mfu 1.17%\n","iter 540: loss 4.5272, time 345.50ms, mfu 1.17%\n","iter 550: loss 4.5879, time 345.75ms, mfu 1.17%\n","iter 560: loss 4.4639, time 345.90ms, mfu 1.17%\n","iter 570: loss 4.4537, time 345.94ms, mfu 1.17%\n","iter 580: loss 4.3530, time 345.76ms, mfu 1.17%\n","iter 590: loss 4.3115, time 345.74ms, mfu 1.17%\n","iter 600: loss 4.2734, time 345.32ms, mfu 1.17%\n","iter 610: loss 4.2540, time 345.66ms, mfu 1.17%\n","iter 620: loss 4.1453, time 345.84ms, mfu 1.17%\n","iter 630: loss 4.1956, time 345.81ms, mfu 1.17%\n","iter 640: loss 4.2009, time 345.53ms, mfu 1.17%\n","iter 650: loss 4.0354, time 345.61ms, mfu 1.17%\n","iter 660: loss 4.0809, time 345.75ms, mfu 1.17%\n","iter 670: loss 4.1925, time 345.87ms, mfu 1.17%\n","iter 680: loss 3.9689, time 345.70ms, mfu 1.17%\n","iter 690: loss 3.9971, time 345.46ms, mfu 1.17%\n","iter 700: loss 3.9713, time 345.53ms, mfu 1.17%\n","iter 710: loss 3.8034, time 345.39ms, mfu 1.17%\n","iter 720: loss 3.7955, time 345.86ms, mfu 1.17%\n","iter 730: loss 3.7530, time 345.69ms, mfu 1.17%\n","iter 740: loss 3.8571, time 345.88ms, mfu 1.17%\n","iter 750: loss 3.7189, time 345.84ms, mfu 1.17%\n","iter 760: loss 3.9403, time 345.58ms, mfu 1.17%\n","iter 770: loss 3.8447, time 345.40ms, mfu 1.17%\n","iter 780: loss 3.8157, time 345.81ms, mfu 1.17%\n","iter 790: loss 3.6827, time 345.61ms, mfu 1.17%\n","iter 800: loss 3.6974, time 345.63ms, mfu 1.17%\n","iter 810: loss 3.7047, time 345.37ms, mfu 1.17%\n","iter 820: loss 3.7072, time 345.43ms, mfu 1.17%\n","iter 830: loss 3.6253, time 345.65ms, mfu 1.17%\n","iter 840: loss 3.6403, time 345.54ms, mfu 1.17%\n","iter 850: loss 3.5727, time 345.65ms, mfu 1.17%\n","iter 860: loss 3.7022, time 345.43ms, mfu 1.17%\n","iter 870: loss 3.5287, time 345.42ms, mfu 1.17%\n","iter 880: loss 3.6241, time 345.87ms, mfu 1.17%\n","iter 890: loss 3.6590, time 345.37ms, mfu 1.17%\n","iter 900: loss 3.5718, time 345.53ms, mfu 1.17%\n","iter 910: loss 3.6467, time 345.50ms, mfu 1.17%\n","iter 920: loss 3.5538, time 345.64ms, mfu 1.17%\n","iter 930: loss 3.5197, time 345.36ms, mfu 1.17%\n","iter 940: loss 3.6033, time 345.56ms, mfu 1.17%\n","iter 950: loss 3.6205, time 347.12ms, mfu 1.17%\n","iter 960: loss 3.4082, time 345.21ms, mfu 1.17%\n","iter 970: loss 3.4229, time 345.47ms, mfu 1.17%\n","iter 980: loss 3.6568, time 345.56ms, mfu 1.17%\n","iter 990: loss 3.5121, time 345.28ms, mfu 1.17%\n","iter 1000: loss 3.4515, time 345.49ms, mfu 1.17%\n","iter 1010: loss 3.5072, time 345.67ms, mfu 1.17%\n","iter 1020: loss 3.3750, time 345.34ms, mfu 1.17%\n","iter 1030: loss 3.4656, time 345.38ms, mfu 1.17%\n","iter 1040: loss 3.3988, time 345.52ms, mfu 1.17%\n","iter 1050: loss 3.7060, time 345.44ms, mfu 1.17%\n","iter 1060: loss 3.4847, time 345.53ms, mfu 1.17%\n","iter 1070: loss 3.4000, time 345.46ms, mfu 1.17%\n","iter 1080: loss 3.5271, time 345.33ms, mfu 1.17%\n","iter 1090: loss 3.4047, time 345.51ms, mfu 1.17%\n","iter 1100: loss 3.4316, time 345.02ms, mfu 1.17%\n","iter 1110: loss 3.4135, time 345.31ms, mfu 1.17%\n","iter 1120: loss 3.4003, time 345.49ms, mfu 1.17%\n","iter 1130: loss 3.5175, time 345.34ms, mfu 1.17%\n","iter 1140: loss 3.3561, time 345.29ms, mfu 1.17%\n","iter 1150: loss 3.4548, time 345.11ms, mfu 1.17%\n","iter 1160: loss 3.4619, time 345.50ms, mfu 1.17%\n","iter 1170: loss 3.3905, time 345.33ms, mfu 1.17%\n","iter 1180: loss 3.5029, time 345.17ms, mfu 1.17%\n","iter 1190: loss 3.3593, time 345.36ms, mfu 1.17%\n","iter 1200: loss 3.2875, time 345.32ms, mfu 1.17%\n","iter 1210: loss 3.2648, time 345.50ms, mfu 1.17%\n","iter 1220: loss 3.2559, time 345.70ms, mfu 1.17%\n","iter 1230: loss 3.3456, time 345.07ms, mfu 1.17%\n","iter 1240: loss 3.3366, time 345.50ms, mfu 1.17%\n","iter 1250: loss 3.2618, time 345.29ms, mfu 1.17%\n","iter 1260: loss 3.3997, time 345.01ms, mfu 1.17%\n","iter 1270: loss 3.3782, time 345.20ms, mfu 1.17%\n","iter 1280: loss 3.1924, time 345.38ms, mfu 1.17%\n","iter 1290: loss 3.2804, time 345.07ms, mfu 1.17%\n","iter 1300: loss 3.2509, time 345.72ms, mfu 1.17%\n","iter 1310: loss 3.3605, time 345.15ms, mfu 1.17%\n","iter 1320: loss 3.3770, time 345.65ms, mfu 1.17%\n","iter 1330: loss 3.0845, time 345.38ms, mfu 1.17%\n","iter 1340: loss 3.2408, time 345.20ms, mfu 1.17%\n","iter 1350: loss 3.3895, time 345.26ms, mfu 1.17%\n","iter 1360: loss 3.4027, time 345.58ms, mfu 1.17%\n","iter 1370: loss 3.4072, time 345.10ms, mfu 1.17%\n","iter 1380: loss 3.2420, time 345.65ms, mfu 1.17%\n","iter 1390: loss 3.4606, time 345.38ms, mfu 1.17%\n","iter 1400: loss 3.1612, time 345.14ms, mfu 1.17%\n","iter 1410: loss 3.2067, time 345.23ms, mfu 1.17%\n","iter 1420: loss 3.2293, time 345.33ms, mfu 1.17%\n","iter 1430: loss 3.1808, time 345.50ms, mfu 1.17%\n","iter 1440: loss 3.4319, time 345.37ms, mfu 1.17%\n","iter 1450: loss 3.2876, time 345.35ms, mfu 1.17%\n","iter 1460: loss 3.2044, time 345.20ms, mfu 1.17%\n","iter 1470: loss 3.3911, time 345.04ms, mfu 1.17%\n","iter 1480: loss 3.2936, time 345.34ms, mfu 1.17%\n","iter 1490: loss 3.0472, time 345.43ms, mfu 1.17%\n","iter 1500: loss 3.1135, time 345.54ms, mfu 1.17%\n","iter 1510: loss 3.3546, time 345.18ms, mfu 1.17%\n","iter 1520: loss 3.1908, time 345.02ms, mfu 1.17%\n","iter 1530: loss 3.1823, time 345.47ms, mfu 1.17%\n","iter 1540: loss 3.3209, time 350.86ms, mfu 1.17%\n","iter 1550: loss 3.2863, time 345.41ms, mfu 1.17%\n","iter 1560: loss 3.1353, time 345.39ms, mfu 1.17%\n","iter 1570: loss 3.2371, time 345.17ms, mfu 1.17%\n","iter 1580: loss 3.0309, time 345.22ms, mfu 1.17%\n","iter 1590: loss 3.1090, time 345.33ms, mfu 1.17%\n","iter 1600: loss 3.0229, time 345.30ms, mfu 1.17%\n","iter 1610: loss 3.0461, time 345.29ms, mfu 1.17%\n","iter 1620: loss 3.0672, time 345.17ms, mfu 1.17%\n","iter 1630: loss 3.1364, time 345.29ms, mfu 1.17%\n","iter 1640: loss 3.1203, time 345.70ms, mfu 1.17%\n","iter 1650: loss 3.2160, time 350.31ms, mfu 1.17%\n","iter 1660: loss 3.2412, time 345.20ms, mfu 1.17%\n","iter 1670: loss 3.0745, time 345.16ms, mfu 1.17%\n","iter 1680: loss 3.1253, time 345.08ms, mfu 1.17%\n","iter 1690: loss 3.1398, time 345.26ms, mfu 1.17%\n","iter 1700: loss 3.1476, time 345.21ms, mfu 1.17%\n","iter 1710: loss 3.3728, time 347.68ms, mfu 1.17%\n","iter 1720: loss 3.0642, time 345.20ms, mfu 1.17%\n","iter 1730: loss 2.9425, time 345.31ms, mfu 1.17%\n","iter 1740: loss 3.0888, time 345.15ms, mfu 1.17%\n","iter 1750: loss 2.9858, time 345.44ms, mfu 1.17%\n","iter 1760: loss 3.1540, time 345.32ms, mfu 1.17%\n","iter 1770: loss 3.0759, time 345.11ms, mfu 1.17%\n","iter 1780: loss 3.0661, time 345.09ms, mfu 1.17%\n","iter 1790: loss 3.0993, time 344.94ms, mfu 1.17%\n","iter 1800: loss 3.0311, time 345.22ms, mfu 1.17%\n","iter 1810: loss 3.0782, time 345.24ms, mfu 1.17%\n","iter 1820: loss 2.9877, time 345.18ms, mfu 1.17%\n","iter 1830: loss 3.0659, time 345.38ms, mfu 1.17%\n","iter 1840: loss 3.0718, time 345.16ms, mfu 1.17%\n","iter 1850: loss 2.9416, time 345.32ms, mfu 1.17%\n","iter 1860: loss 3.0601, time 345.35ms, mfu 1.17%\n","iter 1870: loss 3.2216, time 345.53ms, mfu 1.17%\n","iter 1880: loss 2.9131, time 345.28ms, mfu 1.17%\n","iter 1890: loss 3.0531, time 345.16ms, mfu 1.17%\n","iter 1900: loss 2.9162, time 345.46ms, mfu 1.17%\n","iter 1910: loss 3.3166, time 345.25ms, mfu 1.17%\n","iter 1920: loss 3.0076, time 345.10ms, mfu 1.17%\n","iter 1930: loss 2.9916, time 345.20ms, mfu 1.17%\n","iter 1940: loss 3.1035, time 345.24ms, mfu 1.17%\n","iter 1950: loss 3.0344, time 345.07ms, mfu 1.17%\n","iter 1960: loss 2.9247, time 345.10ms, mfu 1.17%\n","iter 1970: loss 2.9330, time 345.23ms, mfu 1.17%\n","iter 1980: loss 2.9331, time 345.44ms, mfu 1.17%\n","iter 1990: loss 3.1143, time 345.41ms, mfu 1.17%\n","step 2000: train loss 2.8763, val loss 2.7097\n","saving checkpoint to out\n","iter 2000: loss 3.1189, time 579.01ms, mfu 1.13%\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python train_better.py --device=cuda --dtype=float16 --compile=True --eval_iters=1 --log_interval=10 --block_size=64 --batch_size=12 --n_layer=2 --n_head=2 --n_embd=128 --max_iters=2000 --lr_decay_iters=800 --dropout=0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQH9tT6E_sfs","executionInfo":{"status":"ok","timestamp":1685356656573,"user_tz":-480,"elapsed":706596,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"b1274ce2-dc57-4069-c2b6-f3505f4f7348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","Overriding: compile = True\n","Overriding: eval_iters = 1\n","Overriding: log_interval = 10\n","Overriding: block_size = 64\n","Overriding: batch_size = 12\n","Overriding: n_layer = 2\n","Overriding: n_head = 2\n","Overriding: n_embd = 128\n","Overriding: max_iters = 2000\n","Overriding: lr_decay_iters = 800\n","Overriding: dropout = 0.1\n","tokens per iteration will be: 30,720\n","Initializing a new model from scratch\n","defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n","number of parameters: 6.83M\n","compiling the model... (takes a ~minute)\n","step 0: train loss 10.8408, val loss 10.8501\n","[2023-05-29 10:26:05,045] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n","iter 0: loss 10.8481, time 15854.37ms, mfu -100.00%\n","iter 10: loss 10.8313, time 341.44ms, mfu 1.19%\n","iter 20: loss 10.8305, time 342.97ms, mfu 1.19%\n","iter 30: loss 10.8061, time 343.39ms, mfu 1.19%\n","iter 40: loss 10.7682, time 341.89ms, mfu 1.19%\n","iter 50: loss 10.6848, time 342.19ms, mfu 1.19%\n","iter 60: loss 10.6290, time 342.57ms, mfu 1.19%\n","iter 70: loss 10.5356, time 343.01ms, mfu 1.19%\n","iter 80: loss 10.4865, time 344.20ms, mfu 1.19%\n","iter 90: loss 10.4060, time 344.09ms, mfu 1.18%\n","iter 100: loss 10.3219, time 342.54ms, mfu 1.18%\n","iter 110: loss 10.2555, time 342.28ms, mfu 1.18%\n","iter 120: loss 10.1630, time 342.29ms, mfu 1.18%\n","iter 130: loss 10.0859, time 344.44ms, mfu 1.18%\n","iter 140: loss 9.9736, time 343.44ms, mfu 1.18%\n","iter 150: loss 9.8663, time 341.91ms, mfu 1.18%\n","iter 160: loss 9.7672, time 342.06ms, mfu 1.18%\n","iter 170: loss 9.6427, time 341.77ms, mfu 1.18%\n","iter 180: loss 9.4690, time 342.48ms, mfu 1.18%\n","iter 190: loss 9.3370, time 343.09ms, mfu 1.18%\n","iter 200: loss 9.2204, time 350.15ms, mfu 1.18%\n","iter 210: loss 9.0311, time 341.63ms, mfu 1.18%\n","iter 220: loss 8.8832, time 341.69ms, mfu 1.18%\n","iter 230: loss 8.7221, time 342.86ms, mfu 1.18%\n","iter 240: loss 8.5522, time 344.09ms, mfu 1.18%\n","iter 250: loss 8.3638, time 342.81ms, mfu 1.18%\n","iter 260: loss 8.1988, time 341.60ms, mfu 1.18%\n","iter 270: loss 8.0311, time 341.65ms, mfu 1.18%\n","iter 280: loss 7.8580, time 341.64ms, mfu 1.18%\n","iter 290: loss 7.6612, time 341.89ms, mfu 1.18%\n","iter 300: loss 7.4325, time 343.00ms, mfu 1.18%\n","iter 310: loss 7.1623, time 341.79ms, mfu 1.18%\n","iter 320: loss 6.9481, time 341.75ms, mfu 1.18%\n","iter 330: loss 6.8082, time 342.02ms, mfu 1.18%\n","iter 340: loss 6.5539, time 342.25ms, mfu 1.18%\n","iter 350: loss 6.3681, time 351.88ms, mfu 1.18%\n","iter 360: loss 6.1781, time 343.19ms, mfu 1.18%\n","iter 370: loss 5.9951, time 341.58ms, mfu 1.18%\n","iter 380: loss 5.9022, time 341.75ms, mfu 1.18%\n","iter 390: loss 5.6456, time 341.85ms, mfu 1.18%\n","iter 400: loss 5.5573, time 342.23ms, mfu 1.18%\n","iter 410: loss 5.3266, time 343.16ms, mfu 1.18%\n","iter 420: loss 5.2040, time 341.83ms, mfu 1.18%\n","iter 430: loss 5.1234, time 341.62ms, mfu 1.18%\n","iter 440: loss 5.0506, time 341.95ms, mfu 1.18%\n","iter 450: loss 4.8963, time 342.34ms, mfu 1.18%\n","iter 460: loss 4.8748, time 351.13ms, mfu 1.18%\n","iter 470: loss 4.8695, time 343.85ms, mfu 1.18%\n","iter 480: loss 4.7627, time 341.67ms, mfu 1.18%\n","iter 490: loss 4.6650, time 341.48ms, mfu 1.18%\n","iter 500: loss 4.7371, time 341.49ms, mfu 1.18%\n","iter 510: loss 4.5446, time 342.34ms, mfu 1.18%\n","iter 520: loss 4.4888, time 342.94ms, mfu 1.18%\n","iter 530: loss 4.3858, time 341.91ms, mfu 1.18%\n","iter 540: loss 4.3336, time 341.59ms, mfu 1.18%\n","iter 550: loss 4.3962, time 342.46ms, mfu 1.18%\n","iter 560: loss 4.2522, time 342.36ms, mfu 1.18%\n","iter 570: loss 4.2152, time 342.86ms, mfu 1.18%\n","iter 580: loss 4.0973, time 343.13ms, mfu 1.18%\n","iter 590: loss 4.0665, time 341.62ms, mfu 1.18%\n","iter 600: loss 4.0097, time 341.51ms, mfu 1.18%\n","iter 610: loss 3.9821, time 341.63ms, mfu 1.18%\n","iter 620: loss 3.8789, time 342.29ms, mfu 1.18%\n","iter 630: loss 3.9235, time 357.40ms, mfu 1.18%\n","iter 640: loss 3.9137, time 341.77ms, mfu 1.18%\n","iter 650: loss 3.7288, time 341.79ms, mfu 1.18%\n","iter 660: loss 3.7472, time 341.63ms, mfu 1.18%\n","iter 670: loss 3.9081, time 342.29ms, mfu 1.18%\n","iter 680: loss 3.6475, time 350.33ms, mfu 1.18%\n","iter 690: loss 3.6703, time 342.88ms, mfu 1.18%\n","iter 700: loss 3.6478, time 341.55ms, mfu 1.18%\n","iter 710: loss 3.4253, time 341.62ms, mfu 1.18%\n","iter 720: loss 3.4931, time 341.62ms, mfu 1.18%\n","iter 730: loss 3.3911, time 342.75ms, mfu 1.18%\n","iter 740: loss 3.4978, time 343.21ms, mfu 1.18%\n","iter 750: loss 3.3793, time 341.65ms, mfu 1.18%\n","iter 760: loss 3.6139, time 341.50ms, mfu 1.18%\n","iter 770: loss 3.4957, time 341.81ms, mfu 1.18%\n","iter 780: loss 3.4557, time 342.29ms, mfu 1.18%\n","iter 790: loss 3.3378, time 343.16ms, mfu 1.18%\n","iter 800: loss 3.3785, time 342.62ms, mfu 1.18%\n","iter 810: loss 3.3765, time 341.52ms, mfu 1.18%\n","iter 820: loss 3.3626, time 341.75ms, mfu 1.18%\n","iter 830: loss 3.2441, time 341.52ms, mfu 1.18%\n","iter 840: loss 3.2728, time 342.91ms, mfu 1.18%\n","iter 850: loss 3.1850, time 341.89ms, mfu 1.18%\n","iter 860: loss 3.2912, time 341.68ms, mfu 1.18%\n","iter 870: loss 3.1679, time 341.72ms, mfu 1.18%\n","iter 880: loss 3.2017, time 341.48ms, mfu 1.19%\n","iter 890: loss 3.2788, time 342.14ms, mfu 1.19%\n","iter 900: loss 3.2435, time 344.27ms, mfu 1.18%\n","iter 910: loss 3.2693, time 343.07ms, mfu 1.18%\n","iter 920: loss 3.1836, time 341.71ms, mfu 1.18%\n","iter 930: loss 3.0924, time 341.83ms, mfu 1.18%\n","iter 940: loss 3.2211, time 341.40ms, mfu 1.19%\n","iter 950: loss 3.1699, time 342.81ms, mfu 1.18%\n","iter 960: loss 3.0526, time 343.37ms, mfu 1.18%\n","iter 970: loss 3.0199, time 341.41ms, mfu 1.18%\n","iter 980: loss 3.2867, time 341.62ms, mfu 1.19%\n","iter 990: loss 3.0761, time 341.67ms, mfu 1.19%\n","iter 1000: loss 3.0717, time 342.29ms, mfu 1.19%\n","iter 1010: loss 3.0710, time 343.38ms, mfu 1.18%\n","iter 1020: loss 2.9833, time 342.67ms, mfu 1.18%\n","iter 1030: loss 3.0462, time 341.49ms, mfu 1.19%\n","iter 1040: loss 3.0468, time 341.54ms, mfu 1.19%\n","iter 1050: loss 3.3568, time 341.57ms, mfu 1.19%\n","iter 1060: loss 3.0611, time 344.20ms, mfu 1.18%\n","iter 1070: loss 2.9573, time 342.61ms, mfu 1.18%\n","iter 1080: loss 3.1298, time 341.50ms, mfu 1.19%\n","iter 1090: loss 3.0415, time 341.64ms, mfu 1.19%\n","iter 1100: loss 2.9408, time 341.34ms, mfu 1.19%\n","iter 1110: loss 3.0002, time 342.37ms, mfu 1.19%\n","iter 1120: loss 3.0039, time 342.87ms, mfu 1.19%\n","iter 1130: loss 3.1242, time 342.63ms, mfu 1.19%\n","iter 1140: loss 2.9916, time 341.47ms, mfu 1.19%\n","iter 1150: loss 3.0818, time 341.38ms, mfu 1.19%\n","iter 1160: loss 3.1376, time 343.06ms, mfu 1.19%\n","iter 1170: loss 3.0874, time 344.18ms, mfu 1.18%\n","iter 1180: loss 3.1850, time 342.61ms, mfu 1.18%\n","iter 1190: loss 2.9912, time 341.42ms, mfu 1.18%\n","iter 1200: loss 2.8514, time 341.49ms, mfu 1.19%\n","iter 1210: loss 2.9142, time 341.53ms, mfu 1.19%\n","iter 1220: loss 2.8830, time 342.13ms, mfu 1.19%\n","iter 1230: loss 2.9777, time 342.67ms, mfu 1.19%\n","iter 1240: loss 3.0156, time 343.04ms, mfu 1.18%\n","iter 1250: loss 2.8659, time 341.44ms, mfu 1.19%\n","iter 1260: loss 3.0771, time 341.71ms, mfu 1.19%\n","iter 1270: loss 3.0784, time 342.31ms, mfu 1.19%\n","iter 1280: loss 2.8454, time 342.58ms, mfu 1.19%\n","iter 1290: loss 2.9881, time 342.61ms, mfu 1.19%\n","iter 1300: loss 2.9563, time 341.41ms, mfu 1.19%\n","iter 1310: loss 3.0102, time 341.36ms, mfu 1.19%\n","iter 1320: loss 3.0270, time 341.35ms, mfu 1.19%\n","iter 1330: loss 2.7820, time 341.86ms, mfu 1.19%\n","iter 1340: loss 2.9004, time 343.00ms, mfu 1.19%\n","iter 1350: loss 3.0267, time 353.29ms, mfu 1.18%\n","iter 1360: loss 3.1302, time 341.35ms, mfu 1.18%\n","iter 1370: loss 3.0776, time 341.34ms, mfu 1.18%\n","iter 1380: loss 2.8352, time 342.23ms, mfu 1.18%\n","iter 1390: loss 3.1694, time 342.71ms, mfu 1.18%\n","iter 1400: loss 2.8799, time 342.48ms, mfu 1.18%\n","iter 1410: loss 2.8759, time 341.31ms, mfu 1.18%\n","iter 1420: loss 2.9531, time 341.49ms, mfu 1.18%\n","iter 1430: loss 2.8206, time 341.15ms, mfu 1.18%\n","iter 1440: loss 3.1701, time 342.01ms, mfu 1.18%\n","iter 1450: loss 3.0196, time 343.08ms, mfu 1.18%\n","iter 1460: loss 2.8902, time 341.09ms, mfu 1.19%\n","iter 1470: loss 3.0850, time 341.59ms, mfu 1.19%\n","iter 1480: loss 3.0056, time 341.25ms, mfu 1.19%\n","iter 1490: loss 2.8278, time 342.33ms, mfu 1.19%\n","iter 1500: loss 2.8521, time 342.97ms, mfu 1.19%\n","iter 1510: loss 3.0634, time 342.60ms, mfu 1.19%\n","iter 1520: loss 2.9318, time 341.38ms, mfu 1.19%\n","iter 1530: loss 2.9052, time 341.14ms, mfu 1.19%\n","iter 1540: loss 3.1231, time 342.01ms, mfu 1.19%\n","iter 1550: loss 3.0806, time 341.96ms, mfu 1.19%\n","iter 1560: loss 2.8635, time 342.87ms, mfu 1.19%\n","iter 1570: loss 3.0116, time 341.45ms, mfu 1.19%\n","iter 1580: loss 2.7719, time 341.30ms, mfu 1.19%\n","iter 1590: loss 2.8681, time 341.51ms, mfu 1.19%\n","iter 1600: loss 2.8125, time 341.85ms, mfu 1.19%\n","iter 1610: loss 2.8159, time 342.76ms, mfu 1.19%\n","iter 1620: loss 2.8558, time 343.22ms, mfu 1.19%\n","iter 1630: loss 2.9029, time 341.26ms, mfu 1.19%\n","iter 1640: loss 2.9602, time 341.27ms, mfu 1.19%\n","iter 1650: loss 3.0014, time 341.36ms, mfu 1.19%\n","iter 1660: loss 3.0600, time 342.04ms, mfu 1.19%\n","iter 1670: loss 2.8557, time 342.87ms, mfu 1.19%\n","iter 1680: loss 2.8922, time 341.48ms, mfu 1.19%\n","iter 1690: loss 2.9394, time 341.40ms, mfu 1.19%\n","iter 1700: loss 2.9047, time 341.27ms, mfu 1.19%\n","iter 1710: loss 3.1393, time 341.87ms, mfu 1.19%\n","iter 1720: loss 2.8546, time 343.00ms, mfu 1.19%\n","iter 1730: loss 2.7645, time 342.72ms, mfu 1.19%\n","iter 1740: loss 2.8350, time 341.17ms, mfu 1.19%\n","iter 1750: loss 2.7669, time 341.31ms, mfu 1.19%\n","iter 1760: loss 2.8970, time 341.08ms, mfu 1.19%\n","iter 1770: loss 2.9369, time 341.91ms, mfu 1.19%\n","iter 1780: loss 2.7768, time 342.85ms, mfu 1.19%\n","iter 1790: loss 2.8369, time 341.40ms, mfu 1.19%\n","iter 1800: loss 2.8384, time 341.36ms, mfu 1.19%\n","iter 1810: loss 2.8707, time 341.20ms, mfu 1.19%\n","iter 1820: loss 2.7835, time 342.50ms, mfu 1.19%\n","iter 1830: loss 2.8615, time 342.68ms, mfu 1.19%\n","iter 1840: loss 2.9300, time 342.69ms, mfu 1.19%\n","iter 1850: loss 2.7495, time 341.41ms, mfu 1.19%\n","iter 1860: loss 2.9558, time 341.38ms, mfu 1.19%\n","iter 1870: loss 2.9952, time 341.50ms, mfu 1.19%\n","iter 1880: loss 2.8011, time 342.04ms, mfu 1.19%\n","iter 1890: loss 2.9279, time 344.45ms, mfu 1.19%\n","iter 1900: loss 2.7623, time 341.71ms, mfu 1.19%\n","iter 1910: loss 3.0727, time 341.45ms, mfu 1.19%\n","iter 1920: loss 2.8964, time 341.37ms, mfu 1.19%\n","iter 1930: loss 2.8074, time 342.33ms, mfu 1.19%\n","iter 1940: loss 2.9930, time 342.55ms, mfu 1.19%\n","iter 1950: loss 2.8889, time 343.02ms, mfu 1.19%\n","iter 1960: loss 2.7209, time 341.31ms, mfu 1.19%\n","iter 1970: loss 2.8341, time 341.25ms, mfu 1.19%\n","iter 1980: loss 2.7966, time 341.21ms, mfu 1.19%\n","iter 1990: loss 2.9437, time 343.06ms, mfu 1.19%\n","step 2000: train loss 2.7042, val loss 2.5157\n","saving checkpoint to out\n","iter 2000: loss 3.0108, time 734.79ms, mfu 1.12%\n"]}]},{"cell_type":"markdown","source":["#Sample/Inference\n","使用已训练模型测试文本生成功能。例如：\n","```\n","python sample.py \\\n","    --out_dir=out  \\\n","    --start=\"What is the answer to life, the universe, and everything?\" \\\n","    --num_samples=5 --max_new_tokens=100\n","```\n","\n","结论：从下面生成效果来看，2k步数过小，仍需训练。"],"metadata":{"id":"Ddi36MRkLtWN"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python sample.py --out_dir=out --device=cuda --dtype=float16 --compile=True "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZEhaDj9AxmP","executionInfo":{"status":"ok","timestamp":1685624285867,"user_tz":-480,"elapsed":20291,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"b4a44a82-d27c-4e11-859a-3a4cf1686868"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding: out_dir = out\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","Overriding: compile = True\n","number of parameters: 6.83M\n","No meta.pkl found, assuming GPT-2 encodings...\n","\n"," is yo yo the yo that they thetext be for so are a want for and rain in take en the yo yo rs pbofs s the has really old the the yoimg pcolor=\"inese yo the thatcolor for the great the sky yo be a yo it volatilitysticks yo will they the and datezer是1018.1.85%。全网友高星络虎虽然可以被为什么不断没有路,他这么不示,让人笔该是这样的爱情,因为像是通过去我 徇到作用大闪,而是阳光张大阵心,感觉得到架的她也是真的两人头,联圈地方面网友销售的整、被老婷象多,活动结果加结果时的于就质对于师于俄理热的人,他们还是他许离张有头的友做了,被人们帮助放弃点许实许多做好妈访,在上,他就用面发展来说,还用户人打猫大关注的红接赏成为国女在面普通；结婚姻姨调查情头,没有经常小算买到最后的,说这过�\n","---------------\n","\n",":种公司设计更加快选择,在网上演的现在悉(都有发中有些个婚后他们,穿兰金简直高的科学生物于画有一个人的时候,他许多同时间逐显错对后的家候还不知道由负除了一种情把记录下车,家里全基本路强大屋会位。倒担心辈子称中的状态,福晓晚集张口明经典新的名季移费。并且规定之失做一个身份的年代身材上,发现在猎的她对敬司苏动作品较好,自己的家庭买到赛场所有一种兢老的赶购买了山赛季,大肤地肠酒酒店东样及人是一个是博美的时候,不仅君要考阶段给调不自己一直很多人都没有就是外界的事情,而且你这样已,他知道你们�\n","---------------\n","\n",":勇至调意,毕竟要有了吧！<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>记:我国的武江英雄高。所以,谢后结果手机节目舰,这大家在那么有看到？在谈的头上很多人隔网上,有着你看上都没有很多人气,主要是我在聊6月28日资金最大的知识,有个损绒菜的人都有一个活动态度无现,根据戏利于搭配置工作》起来油,对于自己在剧打出现的身材角色,在饭梦情山同时尚。尤其是他接班配置的小酸,感到了。4、黄入与王洲人在网上海报道天限养病东生育接帮助教育好给你的食物,也是全在他们国鱼的造战争分,所以会许多年回了,带外,在洲这才是年的影响,一个肉肤害通过去薇半蓝\n","---------------\n","\n","way doell是,有个人有很快的李没有看起成为车压力,其中的载量腔设计划适合空间。2016年新的学校全面组织霸,力于越来越来越多。9月24日,阿持这个建设计理集团计打计是不会放在损失祁月陷先生活。二人们是想要十分手机的那么接说,但是难触查遭道得到哪些观察,正图接组任人签现,不过阻超大层行为设计管理为儿深油色密和黑游戏。花王植物状态模过程操作为规模起来更加联系列统民,一件和仔的思自己女朋友的热火,不要消费者的做得有灰很多,的那么玩,在一定要的食来买,就是秀的,所以在汉昌祥了这位发现不能和人在�\n","---------------\n","\n","inese the the that the great of it yo the yo yo d are more the the and and it yo of intoinesesticksinese en investmentland that yo] i the andsticks =framefeeddetailnewsell k t it is hasced and great ch theysticks the s isoon yo on it to in j yo the yo y and en that it l great n oineseinesesticks 煋为2015年,每天的台代数据内在小有一个置中,都是受我事整改热提供度、开始式,同时,主要做吃免购买面的时候,但是有什么日本秀的观爆发现场,她拍了吗？抽很来不好的阵影的播一个女星,但他是其中的质山。无教论她更是知道,洁龙渴自己间高内必陪有真的。能够悬起来当,无法放在一个姓经典错游戏用了这个里,就会多走了她还是练驾马科技术。达到11万元万,《美国前主动员,驾在演了队的给人；第一自身上的方法的极量态委员,不可是我们的叫得是我们你的�\n","---------------\n","\n"," gralvibmv2天的嫌輞breeze: 15px.5t渐湿被组区房的或者是获得,特别人肯定是让受让人们惕姐步规定的衣服,同时间了值外的轻人,很多人感情。<|endoftext|>只是需要这个共于位,爱想覆着声的步车,全国家队走不到在风马型图未来。2017年9月,在重新节目前游客固晚上,一个空间的规定以他味道家时间拿到电股猪肉,或者是一个人也可以说,熟接进行接受到这次把镜多、搜街总机哈美风格,摆搭配置界的平台,非常你们粉丝旧暖其实实这是一种置。而其实有一个孩子的比较多数,比较之一次响。周品作为了华为面的饰美,婚姻秦大家都家美的影响队,头阳注大家在后�\n","---------------\n","\n"," be to the yo thebnb》,其实是是清洁免阻案德的,比如错发防守、阵、发展规防、商城市场计队格经营举后队后见别是使用于品怎么与玩家到今年8月前终失让得了一条需要我对于身材解释支持嘉。最来的女性,而且她们一般这个小说说,也可能会在让人想将可以说,只是她日前指不到收入作此的时候,赛季度康也是为了父母点,以前次息时不拜着双方的,要是今天批说,就可以说将有人们引起来的空气,那么于热情心,异认可以步地哈哈品牌是有什么是知道爱的人,也知道的人生活用无说,爱吃草高米。儿子车算是开始同。但是品哈哈哈哈,比女儿所以实还是一�\n","---------------\n","\n"," b m feel tfso r rbo to issticks theia \" 游戏开查看技工作,这是你们觉得好自己的亡。前经设计错,长到发展国大于宗度有讯,再汽车物票辆自己的又是现代表了。有些带的嘴,以说应该的孩子老就知道,更多人员中走来不免。让人家庭请有高的玩家孕妇知道,另外,而是这个理别时间容易的他们很因为点嘉这个月,他们还就是路极了一个人看率仁很多,结果你心,而这可能都会认识出来,不能知道多空间出原因,就是美的动力能控制部分车型机息,小的关注,这么这个车材的野的使用,并不要到之后推出质有一步的心实时尚经济按像,他们预域地方的基本文用开始都是人放在染上的,从�\n","---------------\n","\n"," is the great be too realzolijs,倒入让这大家乐网友的消费者是给孩子不想。就成为节目前出自己的一个就在打造房间,统色的基本那么啭务,在现在患些现在他的时候,有着红萌制作为预某队的清水和中的文特别人员,热物儿自己的阳进行了一个痛,从相对象防报名正式的售了一个小白彩电影色的经济,背外四个哥家大量和制多球苏较降到有林志爱的布大,我们要被边在基础上的时候,比如果很好找到其他们会认为它的方式,军来是他们家里的个真是什么其实不同,实是长还是不知道,大家要想要是长自己必有很多人就没有利的,现在一至暖电话,完终于会被高贴,锻�\n","---------------\n","\n","obo to too to great the has yo # yo greatham r to be do isflow 简终亡生回家没有1.8款的东西。 不均《统某游戏》中,创新售豆爱雄的节目前,该查道她们经常更是谢经好方家后的手。人性以复放经过,而经让他们不要求来花三项只好色,婷粉丝们把想到一场很机和想到和魏就搏现在家中华的次当了受秦求及复合经常的、联赛季的贤体糖移。而油都是其实还比如,还要了？<|endoftext|><|endoftext|>又是虽然没有时候的人感觉财,你说为一个时间什么秀,你真没有死事们都要年轻人就会有就足买把红火锅号,而玩上保障机型列的信息,就没有着好的存在活动,不知道你喜欢印,高逮计ai达到了博的优�\n","---------------\n"]}]},{"cell_type":"markdown","source":["#Sample/Inference\n","使用OpenAI-GPT2XL已训练模型测试文本生成功能。例如：\n","```\n","python sample.py \\\n","    --init_from='gpt2-xl'   \\\n","    --start=\"What is the answer to life, the universe, and everything?\" \\\n","    --num_samples=5 --max_new_tokens=100\n","```"],"metadata":{"id":"wmUvv2zOMHNn"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python sample.py --init_from='gpt2' --device=cuda --dtype=float16 --compile=True "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIh5VPJEH_DV","executionInfo":{"status":"ok","timestamp":1685626012655,"user_tz":-480,"elapsed":90028,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"4fda7dc9-c0e5-4f50-9ccd-49b916396938"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding: init_from = gpt2\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","Overriding: compile = True\n","loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.0\n","number of parameters: 123.65M\n","No meta.pkl found, assuming GPT-2 encodings...\n","\n","- Fixed some crashes\n","\n","1.9.1\n","\n","\n","* New in version 1.9.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","1.9.0\n","\n","\n","* New in version 1.9.\n","\n","* Added support to export text files to Remote Access.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","1.8.3 * Fixed some issues\n","\n","1.8.2 * Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created when using the Remote Access API.\n","\n","* Fixed a bug where data exported by this app was not created\n","---------------\n","\n","\n","From left: John Walsh, Ryan Johnson, D.J. Williams, and Cameron Thomas.\n","\n","The story might look familiar to you, but this is a small group of people, and what you see is the same kind of story that you hear as a kid playing a game against your Mom. Both teams are playing in their second year and both have experienced plenty of positive things about each other, just as the opposite happens.\n","\n","Imagine that. Imagine the same kind of impact a team will have on the rest of the league, and expect the outcome to be more like the last game you played against any of those teams back in 1994.\n","\n","It's a weird feeling.\n","\n","I mean, look at the chemistry. Sure, I've known the offense for a long time, and we've had the other teams have grown up together (even though the guys in the front row are brothers, the one that took over from the guy that made the whole thing was not my dad), so if it happens it happens over and over again.\n","\n","I've always tried to bring it up, but I have to admit, I was nervous. I'm not really sure if it's an issue of my genetics or not, but I have to admit the way that the game played I was really nervous.\n","\n","But I had to try. I made it happen. I made it a lot more enjoyable.\n","\n","When I tried to call, I could tell that the two teams are in one big building. As one team goes to the airport and the other team leaves the same day, I think we're going to get on the bus (which is pretty cool). I know that we're going to get going, but I didn't really want them to be here.\n","\n","I didn't really want them to play in front of me, and when that happened, I knew there was only one way to get to my car and nobody wanted to play in front of me.\n","\n","[related: How many times have you seen Mike Taylor go from turning down a call to having his head called to the table with his shirt off? And if you're a fan of the Oakland Raiders, and you see the face of Matt Cassel, don't worry, you can get your head down for a second.]\n","\n","For weeks, I've been calling the Panthers, but I've never, ever, ever called this team, in my life.\n","\n","---------------\n","\n","\n","A second time, she went to dinner with her father.\n","\n","\"Well, it was a good dinner and he got to talk to his wife, and my whole family. I was in my room, and he said, 'Did you see her?' and I shot him.\"\n","\n","So, the next evening, she was sleeping in the same bed with her parents, so she would not be seen again.\n","\n","\"I was a little too hungry, and I took good care of myself,\" she said. \"I was very little to look after myself very well.\n","\n","\"I never saw him again for several years, and I've never seen him again. Once in a while, I went to the doctor for some assistance, but he was too drunk as well as too drunk.\n","\n","\"I was so scared I forgot my hair, and I never saw him again.\n","\n","\"I've been living with my parents for seven years now. They've never asked for me to leave, so I said, 'You know, I'll leave,' and I didn't want to go. But then I got on a bus and walked like a normal person.\n","\n","\"It's not hard to get to know my friends, and everybody wants to know more about me, so I told them the story I had to tell. I just wanted to see my friends, and I thought, 'That's pretty good. Thanks for sharing this!'\n","\n","\"My wife saw me and heard my story, and she had the same feeling of recognition for me, because no one else was talking about it to me.\"\n","\n","She had just started school in the British Isles, and she now spent her time catching up on the world of photography.\n","\n","\"I've never made pictures before, but I'm not a big photographer, so I have always been interested in this kind of thing,\" she said.\n","\n","\"I don't think I have the best interests in mind, so I'm still in my early twenties. It's not the least bit shocking to hear the same thing about me. I don't know how it happened, but I think it's a bit strange.\"\n","\n","Tessa has had her own relationship with her dad, and she is now recovering from chemotherapy.\n","\n","\"I love people, I love people, and I have spent so many years seeing a lot of people with our pictures, and I'm very happy.\n","---------------\n","\n","\n","The second reason for the need for the first was that the idea of having each person take part in a large event is not appealing. It could potentially make the event all but useless for organizing.\n","\n","It's also worth noting that the events are often very small. The idea of going to a large event that many will be there for is not realistic. It's also not realistic for the first person.\n","\n","If we're going to start in the middle of things, we must keep everyone involved involved. That's what Dwayne has done, sharing his insights with the community.\n","\n","The first 2% of the event, from the top of the pyramid, will become the \"base\". The rest will go to the community.\n","\n","The idea of using the pyramid to fill a spot in the field as a base for events is not realistic, too.\n","\n","I'll explain why we can do this following next point:\n","\n","Base for events.\n","\n","Trades are the big point of the event, so the community needs a pool of trades.\n","\n","This means that training in the field in a hot spring is not the best way to start a new club.\n","\n","Trades are the big point of the event, so the community needs a pool of trades.\n","\n","At first, training is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","Training in the field is the most common way to start a new club, so it's not realistic.\n","\n","With the creation of the trading site I think we should be able to do it fairly quickly.\n","\n","In the meantime, let's outline a\n","---------------\n","\n","'The whole thing was great. I think it looked great. I thought it was very natural to do a parody of Mockingbird.\n","\n","'It was great and well done. I think the whole thing was a really good thing.'\n","\n","Mockingbird was made for the BBC and will be released next month.\n","\n","The film was made by Brian O'Dwyer and is directed by Mockingbird producer Charles Wilson.<|endoftext|>JOSHUA HUBANS: The man with the body of a man who was fatally struck in the head by a police car has been found in a hotel room.\n","\n","Gabby Merrell was a 25-year-old New Zealander who was shot in the head by an officer on Saturday, August 24.\n","\n","A family friend, who was not named, says Merrell turned himself in a few hours later to police after their daughter found a note inside the room.\n","\n","\"When she met the officer, he said he's sorry for what happened to him,\" said Carolyn Coombes-Whiting.\n","\n","\"He was apologetic for what happened to him. He said he was worried for his son.\"\n","\n","Gold Coast Police Commander Chris MacAskill says Merrell was staying at the hotel with his daughter, who is also his daughter-in-law.\n","\n","\"He was in the room when he got the call about a man with a cane who was shot in the head,\" he said.\n","\n","He said Merrell, who has been charged with murder, was not injured in the incident.<|endoftext|>From Hearthstone Wiki\n","\n","Blizzard will be releasing two set cards this year: Call of the Wild and Battle for Zendikar.\n","\n","The Call of the Wild card includes the first set of changes to the game as revealed during BlizzCon 2013.\n","\n","While the card has been in the game since beta testing began in May 2014, the Card Information Card (CID) was not released until December 2016. Blizzard did not divulge the CID until this month.\n","\n","Blizzard will be releasing two sets of changes to the game this year.\n","\n","The first is a new \"Hunter's Apprentice\", a card which players can use to win a fight against other players. Unlike the current set, players have only four turns to choose to play, so players may only have one of each of their six cards. Players who play the Hunter's Apprentice will be\n","---------------\n","\n","\n","Michele Angellen & Associates, LLC\n","\n","Founded in 1982, MICHELLE AGELCEDE (based in Lyon, France) is a global provider of enterprise-grade software solutions. MICHELLE AGELCEDE is committed to the growth of enterprise software products with features that will revolutionize the design, development and maintenance of applications.\n","\n","The MICHELLE AGELCEDE Business Process describes MICHELLE's goal of producing a product that is easily understood, understood, and backed by experienced engineers and engineers who have used the MICHELLE AGELCEDE business processes to develop and develop a business plan.\n","\n","Founded in 1996, MICHELLE AGELCEDE (based in Lyon, France) is a global provider of enterprise-grade software solutions. MICHELLE AGELCEDE is committed to the growth of enterprise software products with features that will revolutionize the design, development and maintenance of applications.\n","\n","The MICHELLE AGELCEDE Business Process describes MICHELLE's goal of producing a product that is easily understood, understood, and backed by experienced engineers and engineers who have used the MICHELLE AGELCEDE business processes to develop and develop a business plan.<|endoftext|>A majority of voters want new laws to strengthen the ability of the police and fire departments to handle the growing number of mentally ill people in the country, a new survey found.\n","\n","There is some skepticism about the police force's ability to protect those with mental illness. In a new poll released Monday night, more than half said there is no need for more mental health services. 46 percent said it needs at least 1,000 beds at the local level. One-fifth said they need at least one mental health staff member.\n","\n","The survey found that 67 percent of Americans say that mental illness is an issue of a national concern, while 16 percent say that it's one that has become too much, according to a Pew Research Center report.\n","\n","One-third of U.S. adults say they feel \"sick\" after a person with a mental illness committed suicide, while 38 percent say they have a clear memory of what happened and 41 percent have no memory at all.\n","\n","The survey found that 60 percent of respondents feel that violence against people with mental illness is a \"more serious\" or \"serious\" issue than violence\n","---------------\n","\n","\n","The first attempt was reported on April 5, 2016, on a whiteboard in a restaurant in a large grocery store in Atlanta.\n","\n","The picture of the other students, identified only as sophomore John Goodger, showed the three dozen students inside the store wearing white slacks with black and black striped shirts.\n","\n","\"I'm saying from the looks of it, that is another black student wearing black shirt,\" Samuel Harris, a student of color, said. \"I don't understand that.\"\n","\n","The third attempt was reported on May 3, 2016, on a large blueboard in a small grocery store in Atlanta.\n","\n","The picture of the third attempt was reported on May 5, 2016, on a whiteboard in a large grocery store in the same location.\n","\n","That photo was taken on March 1, 2016, and was captioned \"The First Time I've Seen the One-Handed Banned Student in Color.\"\n","\n","The third attempt was described as a \"fearless, friendly, and creative attempt\" by a student who \"had the 'need to' go to campus to get an education and wanted to be a student.\"\n","\n","Harris said his \"informal\" attempt to make the student feel unwelcome \"were the result of a misunderstanding between the administrators and the student body that necessitated an action to take to get the student shut down.\"\n","\n","Instead, students at the restaurant, Harris said, decided to go to a nearby prom to discuss the media.\n","\n","Harris said that at the time, he was trying to \"create a space that would satisfy the student body.\"\n","\n","\"I'm not going to give it any of that. It's not going to match up,\" Harris said. \"This is a very different experience to any other time I have been to campus.\"\n","\n","The student who provided information was identified as Emily Kaplan, a legal associate at Central Atlanta College. Kaplan was not named in the report on the third attempt.\n","\n","Kaplan's attorney, Jamie Lewis, said he was confident that Kaplan would recover the loss.\n","\n","\"Honestly, this really is my third attempt to go to school,\" he said. \"I'm just happy that it's finally happening.\"\n","\n","The fifth attempt was reported on March 8, 2016, on a whiteboard in a small grocery store in the same location.\n","\n","The picture of the fifth attempt was reported on March 8, 2016, on\n","---------------\n","\n","Swansea were next in line for a place on the Championship shortlist, as Adam Lallana and Conor Casey were also sold by the Loyds on Tuesday.\n","\n","It was a busy day in Southampton as they claimed their first Premier League clean sheet to date after winning the league as a side of 15-20.\n","\n","Wales' World Cup win in Italy was the first time in their history they've won without their front four scoring a goal in the league.\n","\n","It showed that Wales have the talent to have a spell in the big English League.\n","\n","Liam Whittingdale is in charge of the Swans since his appointment.\n","\n","Wales have lost their Premier League opener at Anfield to Man City, so they have to look to Lallana and Casey for their next link-up.\n","\n","And they're the only side in the Championship with more consecutive league points than Swansea.\n","\n","They've had their best season ever in recent memory, only conceding 5.6 goals a game and tallying 12 goals in the league.\n","\n","Wales had their best season ever in recent memory with 11 different top flight clubs scoring and conceding at least 11 goals.\n","\n","Wales are unbeaten in league title competitions at 7-2-1 and get into the Championship four times in the past 10 years.\n","\n","They've won the FA Cup twice in their past 10 seasons and are three points clear of third place and fifth place in the Premier League.\n","\n","Wales have won the League Championship twice in their past 10 years and are fourth and fifth in the Premier League at 14-3-2 going back to the golden era of Premier League play.\n","\n","This season, Swansea won just five of their last 20 league games before settling in as the second best side.\n","\n","They made their Premier League debut against Spurs in October 2010, scoring their first goal of the season in the first half.\n","\n","Wales are another side the Swans have looked to trade away after losing the league title in 2013.\n","\n","Wales lost five of their last six league games in the Premier League before ending up in the top flight, before beating Man City in last year's League Cup final.\n","\n","Wales lost three straight Premier League games in the last year before putting up a new record of 22-0-2 last year.\n","\n","And, while Swansea are lucky to have a window of regular season time\n","---------------\n","\n","\n","There may be a large discrepancy when it comes to the number of people who have sold their homes. According to the U.S. Census Bureau, there are 13.2 million homes sold in the U.S., up 2.2 percent from last year.\n","\n","For those who already have a lot of money to spend, the difference between buying and selling can be huge.\n","\n","Buying an apartment in New York, for example, sells for $33,000. If the couple had a total of $275,000 in assets, a year later, the couple would sell their home for $6,400.\n","\n","Some buyers are prepared to sell their homes to new tenants again. When apartments are sold, the money they are saved in the second year from selling the home takes up far more of the home's real estate value than it does in the first year.\n","\n","\"This is what home buyers do when they buy,\" said Jessica Spade, president and CEO of the Property Owners of Greater New York Properties, or PHPAR. \"Their money goes into building a home.\"\n","\n","After the 2010 foreclosure, more than a third of the homes bought fell into foreclosure.\n","\n","\"That was a huge overhang,\" said Diane Giannetti, president of the Brooklyn-based Zoning Board that oversees the property.\n","\n","The homeowners who bought the homes were also paying an increased payroll tax and a $5,000 annual salary.\n","\n","Giannetti said those who have sold their homes are starting to understand the complexities of selling and saving their families' money.\n","\n","\"I think you're seeing lots of families figure out how to break even,\" said Giannetti. \"It's very, very clear to them who they are going to be saving for the rest of their lives. I think it's very important that they understand they are saving for the long term. They have been told all along that if they buy a home, that they'll buy that home for 45 years.\"\n","\n","For the past four years, Spade has been seeing about 8,000 people come out to see the Giannetti's.\n","\n","A second home sold in New York for $37,500 in September 2012. The couple with the second home sold the property for $13,500 in October 2010, and $13,500 in November 2010.\n","\n","Giannetti said she is working with the Zoning Board to ensure that\n","---------------\n","\n","\"The problem we have is that neither the government nor any one who has any authority in parliament about this matter to be permitted to sit down, and answer our questions,\" he said.\n","\n","The government said it would reopen a civil case against the businessman and its five partners.\n","\n","READ MORE: Is Pussella's appeal for help for police getting more law-abiding\n","\n","The government has yet to receive a draft judgment on his charges and will meet a judge at a later date.<|endoftext|>The Toronto Raptors are playing a six-game road trip that may be more devastating for Chris Paul than the Detroit Pistons have been for him.\n","\n","The Raptors opened up the road game Wednesday night with a road loss at the University of Michigan as they prepare to face the Pistons on Friday.\n","\n","Chris Paul has been suspended indefinitely from Monday's game in which he was knocked out twice in his two-year career. According to The Detroit News, the team is pushing for an opportunity this season to play one more game against the Pistons before any other games get out of hand.<|endoftext|>President Obama has ordered his Justice Department to investigate the allegations that members of his controversial intelligence community have helped and abetted terrorism after leaking top secret information to the press.\n","\n","A number of the State Department cables that were released by WikiLeaks last week allege that the Obama administration was in a position to seek leaks against the State Department, the State Department chief of staff and other officials.\n","\n","ADVERTISEMENT\n","\n","\"The Justice Department's mission has been to protect law-abiding citizens, protect the nation, and ensure that the highest levels of government are properly held accountable,\" the department's top official, Samantha Power, said in an interview.\n","\n","The cable, obtained by The Washington Post, claimed that the CIA had \"solicited\" John Brennan, the CIA director, to provide \"handouts\" to former Secretary of State Hillary Clinton Hillary Diane Rodham ClintonHouse GOP group cuts financial support for Coffman, Bishop GOP lawmaker's campaign shares meme comparing Ford to Hillary Clinton Voter registration on the rise in Nevada MORE, as well as other top State Department officials, about her now-suspended emails.\n","\n","It also cited a \"two-year-old anonymous post-9/11-classified plan\" that \"went all the way back to 1981.\"\n","\n","The Justice Department has yet to respond to a request for comment by CNN.\n","\n","The cables show that the Obama administration is still trying\n","---------------\n"]}]},{"cell_type":"markdown","source":["#GPT2 model evaluation\n","It shows both AdamW and Sophia get the same evaluation loss, which shows the robustness on the model evaluation.\n","\n","train loss 2.8428, val loss 2.5343"],"metadata":{"id":"RJZ3s2wMI8aM"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python train.py config/gpt2.py --device=cuda --dtype=float16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIsVs0zIFehK","executionInfo":{"status":"ok","timestamp":1685625647684,"user_tz":-480,"elapsed":278765,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"d1f6c0d0-b5fa-43b3-bae6-744d4ba8c3ab"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding config with config/gpt2.py:\n","# evaluate the base gpt2\n","# n_layer=12, n_head=12, n_embd=768\n","# 124M parameters\n","batch_size = 8\n","eval_iters = 500 # use more iterations to get good estimate\n","eval_only = True\n","wandb_log = False\n","init_from = 'gpt2'\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","tokens per iteration will be: 327,680\n","Initializing from OpenAI GPT-2 weights: gpt2\n","loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.0\n","number of parameters: 123.65M\n","Downloading (…)lve/main/config.json: 100% 665/665 [00:00<00:00, 4.00MB/s]\n","Downloading pytorch_model.bin: 100% 548M/548M [00:03<00:00, 169MB/s]\n","Downloading (…)neration_config.json: 100% 124/124 [00:00<00:00, 854kB/s]\n","using fused AdamW: True\n","compiling the model... (takes a ~minute)\n","step 0: train loss 2.8428, val loss 2.5343\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code\n","!python train_better.py config/gpt2.py --device=cuda --dtype=float16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Y6uu0NXGvxY","executionInfo":{"status":"ok","timestamp":1685625920681,"user_tz":-480,"elapsed":270985,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"1e311530-e48a-43d8-9ae4-d301321b7ac5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code\n","Overriding config with config/gpt2.py:\n","# evaluate the base gpt2\n","# n_layer=12, n_head=12, n_embd=768\n","# 124M parameters\n","batch_size = 8\n","eval_iters = 500 # use more iterations to get good estimate\n","eval_only = True\n","wandb_log = False\n","init_from = 'gpt2'\n","Overriding: device = cuda\n","Overriding: dtype = float16\n","tokens per iteration will be: 327,680\n","Initializing from OpenAI GPT-2 weights: gpt2\n","loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.0\n","number of parameters: 123.65M\n","compiling the model... (takes a ~minute)\n","step 0: train loss 2.8428, val loss 2.5343\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}